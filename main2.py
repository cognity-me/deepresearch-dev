#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Advanced Deepâ€‘Research Assistant
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  * ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ë¡œ ì—°êµ¬ íŒŒë¼ë¯¸í„° ìˆ˜ì§‘
  * ì—°êµ¬ ê³„íšì„œ(í”„ë¡¬í”„íŠ¸) í™•ì¸ & ì§„í–‰/ìˆ˜ì •(ìµœëŒ€ 10íšŒ)
  * Deepâ€‘Research ìˆ˜í–‰ ì¤‘ ì‚¬ê³  ê³¼ì •(COT) ì‹¤ì‹œê°„ ë…¸ì¶œ
  * ì™„ë£Œ í›„ Markdown ë³´ê³ ì„œ íŒŒì¼ ì €ì¥
"""

import asyncio
import os
import re
import sys
import json
from datetime import datetime
from typing import Dict, List, Tuple, Optional

from dotenv import load_dotenv
from azure.identity.aio import DefaultAzureCredential
from azure.ai.projects.aio import AIProjectClient
from azure.ai.agents.aio import AgentsClient
from azure.ai.agents.models import (
    DeepResearchTool,
    MessageRole,
    ThreadMessage,
)
from openai import AsyncAzureOpenAI

# ì‚¬ìš©ìâ€‘ê²½í—˜ í™•ë³´ìš© ìƒìˆ˜
MAX_MODIFICATIONS = 10
CONTEXT_KEYS = ["topic", "scope", "depth", "target_audience"]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  Deepâ€‘Research Assistant Class
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class DeepResearchAssistant:
    """AIâ€‘ê¸°ë°˜ ê³ ê¸‰ ë¦¬ì„œì¹˜ ì–´ì‹œìŠ¤í„´íŠ¸"""

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì´ˆê¸°í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def __init__(self):
        self.research_ctx: Dict[str, Optional[str | List[str]]] = {
            "topic": None,
            "scope": None,
            "depth": None,
            "target_audience": None,
            "key_points": [],
        }
        self.conversation_history: List[Tuple[str, str]] = []
        self.modification_count = 0

        # Azure / OpenAI í•¸ë“¤ë“¤
        self.project_client: Optional[AIProjectClient] = None
        self.agents_client: Optional[AgentsClient] = None
        self.agent = None
        self.thread = None
        self.chat_client: Optional[AsyncAzureOpenAI] = None
        self.gpt4o_deployment = None

    async def initialize(self) -> bool:
        """í™˜ê²½ ë³€ìˆ˜ ì½ê³  ê°ì¢… í´ë¼ì´ì–¸íŠ¸ ìƒì„±"""
        load_dotenv()

        try:
            # Deepâ€‘Research
            self.PROJECT_ENDPOINT = os.environ["PROJECT_ENDPOINT"]
            self.DR_MODEL_DEPLOYMENT = os.environ["DEEP_RESEARCH_MODEL_DEPLOYMENT_NAME"]
            self.BING_CONNECTION_NAME = os.environ["BING_RESOURCE_NAME"]
            self.MODEL_DEPLOYMENT_NAME = os.environ["MODEL_DEPLOYMENT_NAME"]

            # GPTâ€‘4oâ€‘mini (ëŒ€í™”)
            gpt_key = os.environ["GPT4O_MINI_API_KEY"]
            gpt_endpoint = os.environ["GPT4O_MINI_ENDPOINT"]
            self.gpt4o_deployment = os.environ["GPT4O_MINI_DEPLOYMENT_NAME"]

        except KeyError as err:
            print(f"âŒ .envâ€¯ì—â€¯{err}â€¯ë³€ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False

        # 1) ëŒ€í™”ìš© GPTâ€‘4oâ€‘mini
        try:
            self.chat_client = AsyncAzureOpenAI(
                api_key=gpt_key,
                azure_endpoint=gpt_endpoint,
                api_version="2025-01-01-preview",
            )
        except Exception as e:
            print(f"âŒ GPTâ€‘4oâ€‘mini ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False

        # 2) Deepâ€‘Researchìš© í´ë¼ì´ì–¸íŠ¸/ì—ì´ì „íŠ¸
        try:
            self.project_client = AIProjectClient(
                endpoint=self.PROJECT_ENDPOINT,
                credential=DefaultAzureCredential(),
            )
            async with self.project_client as pc:
                bing_conn = await pc.connections.get(name=self.BING_CONNECTION_NAME)
                dr_tool = DeepResearchTool(
                    bing_grounding_connection_id=bing_conn.id,
                    deep_research_model=self.DR_MODEL_DEPLOYMENT,
                )
                # agent ìƒì„±
                self.agents_client = pc.agents
                self.agent = await self.agents_client.create_agent(
                    model=self.MODEL_DEPLOYMENT_NAME,
                    name="advanced-research-assistant",
                    instructions=(
                        "You are an advanced research assistant that produces professional, "
                        "wellâ€‘structured research reports with full citations."
                    ),
                    tools=dr_tool.definitions,
                )
                # thread ìƒì„±
                self.thread = await self.agents_client.threads.create()

        except Exception as e:
            print(f"âŒ Deepâ€‘Research ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False

        return True

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ I/O í—¬í¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    async def ainput(self, prompt: str = "") -> str:
        return await asyncio.get_event_loop().run_in_executor(None, input, prompt)

    def pretty_print_welcome(self):
        print("=" * 80)
        print("ğŸ”¬ Advanced Deepâ€‘Research Assistant ğŸ”¬".center(80))
        print("=" * 80)
        print("ìì—°ì–´ ëŒ€í™”ë¥¼ í†µí•´ ì—°êµ¬ ì£¼ì œë¥¼ ì •ì˜í•˜ê³ , ì‹¤ì œ ì‹¬ì¸µ ë¦¬ì„œì¹˜ê¹Œì§€ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n")
        print("â€¢ ì¢…ë£Œí•˜ë ¤ë©´ 'exit' ë˜ëŠ” 'ì¢…ë£Œ' ì…ë ¥\n")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ëŒ€í™” ë‹¨ê³„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    async def get_ai_response(self, user_msg: str) -> Tuple[str, Dict]:
        """GPTâ€‘4oâ€‘mini ì‚¬ìš©, [RESPONSE]/[CONTEXT] êµ¬ì¡° ê°•ì œ"""

        # 1) ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— í˜„ì¬ê¹Œì§€ì˜ ì»¨í…ìŠ¤íŠ¸ ì‚½ì…
        current_ctx = "\n".join(
            f"{k}: {self.research_ctx[k]}" for k in CONTEXT_KEYS if self.research_ctx[k]
        ) or "ì •ë³´ ì—†ìŒ"

        sys_prompt = f"""
You are a concise Korean researchâ€‘needs assistant.

CURRENT_COLLECTED_INFO:
{current_ctx}

RULES:
1. ì‘ë‹µì€ 1â€‘2ë¬¸ì¥.
2. í•œ ë²ˆì— ì§ˆë¬¸ì€ í•˜ë‚˜.
3. ì´ë¯¸ ìˆ˜ì§‘ëœ í•­ëª©ì€ ë¬»ì§€ ë§ ê²ƒ.
4. topicê³¼ scopeê°€ ìˆìœ¼ë©´ is_ready=true.
5. ì‚¬ìš©ì 'ì§„í–‰' ì…ë ¥ ì‹œ is_ready=true.
6. ëŒ€ë‹µì€ ë°˜ë“œì‹œ [RESPONSE] â€¦ [/RESPONSE] ì™€
   [CONTEXT]{{...}}[/CONTEXT] JSON ë¸”ë¡ í¬í•¨.

COLLECT_KEYS: topic, scope, depth(optional), target_audience(optional)

Respond in Korean.
"""

        # 2) ë©”ì‹œì§€ ìŠ¤íƒ
        msgs = [{"role": "system", "content": sys_prompt}]
        for role, content in self.conversation_history[-6:]:
            msgs.append({"role": role, "content": content})
        msgs.append({"role": "user", "content": user_msg})

        # 3) í˜¸ì¶œ
        resp = await self.chat_client.chat.completions.create(
            model=self.gpt4o_deployment,
            messages=msgs,
            temperature=0.7,
            max_tokens=300,
        )
        full = resp.choices[0].message.content

        # 4) íŒŒì‹±
        def extract(tag: str) -> str:
            m = re.search(rf"\[{tag}\](.*?)\[/\s*{tag}\]", full, re.S)
            return m.group(1).strip() if m else ""

        response_text = extract("RESPONSE") or full.strip()
        ctx_json_str = extract("CONTEXT") or "{}"

        try:
            ctx_data = json.loads(ctx_json_str)
        except json.JSONDecodeError:
            ctx_data = {}

        return response_text, ctx_data

    def update_ctx(self, ctx: Dict):
        for k in CONTEXT_KEYS:
            if ctx.get(k):
                self.research_ctx[k] = ctx[k]
        # key_points ë³‘í•©
        if isinstance(ctx.get("key_points"), list):
            for p in ctx["key_points"]:
                if p and p not in self.research_ctx["key_points"]:
                    self.research_ctx["key_points"].append(p)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì—°êµ¬ í”„ë¡¬í”„íŠ¸ ìƒì„± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def build_research_prompt(self) -> str:
        parts = [
            f"Research Topic: {self.research_ctx['topic']}",
            f"Scope/Timeframe: {self.research_ctx['scope']}",
            f"Analysis Depth: {self.research_ctx.get('depth','í‘œì¤€')}",
            f"Target Audience: {self.research_ctx.get('target_audience','ì¼ë°˜')}",
            "",
            "### ìš”êµ¬ ì‚¬í•­",
            "1. Executive Summary",
            "2. Table of Contents",
            "3. Introduction & Background",
            "4. Methodology",
            "5. Main Findings",
            "6. Data Analysis (tables)",
            "7. Visual Insights (charts ì„¤ëª…)",
            "8. Comparative Analysis",
            "9. Challenges & Limitations",
            "10. Conclusions & Recommendations",
            "11. References (with citations)",
            "",
            "â€¢ ë³´ê³ ì„œëŠ” ì£¼ë¡œ í•œêµ­ì–´, í•„ìš” ì‹œ ì˜ë¬¸ ê¸°ìˆ ìš©ì–´ ì‚¬ìš©",
            "â€¢ ë§ˆí¬ë‹¤ìš´ í¬ë§· ì² ì €íˆ ì¤€ìˆ˜",
        ]
        return "\n".join(parts)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Deepâ€‘Research ìˆ˜í–‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    async def run_deep_research(self, prompt: str) -> Optional[ThreadMessage]:
        """ë¦¬ì„œì¹˜ ì‹¤í–‰ & Chainâ€‘ofâ€‘Thought ìŠ¤íŠ¸ë¦¬ë°"""
        print("\nğŸ” Deepâ€‘Research ì‹œì‘\n" + "-" * 60)
        # 1. ì‚¬ìš©ì ë©”ì‹œì§€ ì‚½ì…
        await self.agents_client.messages.create(
            thread_id=self.thread.id, role="user", content=prompt
        )
        # 2. ì‹¤í–‰
        run = await self.agents_client.runs.create(
            thread_id=self.thread.id, agent_id=self.agent.id
        )

        last_msg_id = None
        start = datetime.now()

        # 3. í´ë§
        while run.status in ("queued", "in_progress"):
            await asyncio.sleep(2)
            run = await self.agents_client.runs.get(
                thread_id=self.thread.id, run_id=run.id
            )

            #Â ìƒˆ COT ë©”ì‹œì§€ ì¶œë ¥
            try:
                latest = await self.agents_client.messages.get_last_message_by_role(
                    thread_id=self.thread.id, role=MessageRole.AGENT
                )
                if latest and latest.id != last_msg_id:
                    last_msg_id = latest.id
                    # ëª¨ë“  í…ìŠ¤íŠ¸ í•©ì³ ì¶œë ¥
                    content = "\n".join(t.text.value for t in latest.text_messages)
                    print(f"\nğŸ§  {content}\n" + "-" * 40)
            except Exception:
                pass

            # ì§„í–‰ìƒíƒœ ê°„ë‹¨ í‘œì‹œ
            elapsed = (datetime.now() - start).seconds
            sys.stdout.write(
                f"\râ³ ì§„í–‰ ì¤‘â€¦ {elapsed//60:02d}:{elapsed%60:02d}  ìƒíƒœ: {run.status} "
            )
            sys.stdout.flush()

        print()  # ì¤„ë°”ê¿ˆ

        if run.status == "failed":
            print(f"âŒ ë¦¬ì„œì¹˜ ì‹¤íŒ¨: {run.last_error}")
            return None

        final_msg = await self.agents_client.messages.get_last_message_by_role(
            thread_id=self.thread.id, role=MessageRole.AGENT
        )
        print("âœ… Deepâ€‘Research ì™„ë£Œ!")
        return final_msg

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë³´ê³ ì„œ ì €ì¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def save_markdown(self, msg: ThreadMessage) -> Optional[str]:
        if not msg:
            return None
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        safe_topic = re.sub(r"[^\w\s-]", "", self.research_ctx["topic"] or "report")
        fname = f"research_{safe_topic[:40]}_{timestamp}.md"

        body = "\n\n".join(t.text.value for t in msg.text_messages)
        header = (
            f"# ğŸ“Š Research Report â€“ {self.research_ctx['topic']}\n"
            f"**Generated:** {datetime.now():%Y-%m-%d %H:%M}\n"
            f"**Scope:** {self.research_ctx['scope']}  "
            f"**Depth:** {self.research_ctx.get('depth','í‘œì¤€')}  "
            f"**Audience:** {self.research_ctx.get('target_audience','ì¼ë°˜')}\n\n---\n"
        )

        with open(fname, "w", encoding="utf-8") as fp:
            fp.write(header + body)

        return fname

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë©”ì¸ ëŒ€í™” ë£¨í”„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    async def chat_loop(self):
        self.pretty_print_welcome()
        while True:
            user_in = await self.ainput("ğŸ’¬ ë‹¹ì‹ : ")

            if user_in.lower() in {"exit", "ì¢…ë£Œ"}:
                print("ğŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break

            # ì €ì¥
            self.conversation_history.append(("user", user_in))

            # GPTâ€‘ì‘ë‹µ
            ai_resp, ctx = await self.get_ai_response(user_in)
            self.update_ctx(ctx)

            # íˆìŠ¤í† ë¦¬
            self.conversation_history.append(("assistant", ai_resp))
            print(f"\nğŸ¤– {ai_resp}")

            # ready?
            if ctx.get("is_ready") and self.research_ctx["topic"]:
                await self.confirm_and_research()

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ê³„íšì„œ í™•ì¸ & ì§„í–‰/ìˆ˜ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    async def confirm_and_research(self):
        """ì—°êµ¬ ê³„íšì„œ ë³´ì—¬ì£¼ê³  ì§„í–‰ ì—¬ë¶€ í™•ì¸, ìˆ˜ì • ë£¨í”„(â‰¤10íšŒ)"""

        while True:
            print("\n" + "=" * 70)
            print("ğŸ“‹ ì—°êµ¬ ê³„íšì„œ")
            print("=" * 70)
            for k in CONTEXT_KEYS:
                print(f"{k.capitalize():>15}: {self.research_ctx.get(k) or '(ì—†ìŒ)'}")
            if self.research_ctx["key_points"]:
                print("    Key Points :", ", ".join(self.research_ctx["key_points"]))
            print("=" * 70)

            choice = (await self.ainput("ì§„í–‰(p) / ìˆ˜ì •(m) / ì·¨ì†Œ(c) > ")).lower().strip()
            if choice in {"p", "", "ì§„í–‰"}:
                # ì‹¤ì œ ë¦¬ì„œì¹˜ ì‹œì‘
                prompt = self.build_research_prompt()
                final_msg = await self.run_deep_research(prompt)
                fname = self.save_markdown(final_msg)
                if fname:
                    print(f"\nğŸ“„ ë³´ê³ ì„œ ì €ì¥: {fname}\n")
                return

            elif choice in {"m", "ìˆ˜ì •"}:
                if self.modification_count >= MAX_MODIFICATIONS:
                    print("âš ï¸ ìˆ˜ì • í•œë„(10íšŒ)ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤. ë°”ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")
                    prompt = self.build_research_prompt()
                    final_msg = await self.run_deep_research(prompt)
                    fname = self.save_markdown(final_msg)
                    if fname:
                        print(f"\nğŸ“„ ë³´ê³ ì„œ ì €ì¥: {fname}\n")
                    return
                self.modification_count += 1
                to_fix = await self.ainput(
                    f"ìˆ˜ì •í•  ë‚´ìš©ì„ ë§ì”€í•˜ì„¸ìš” ({self.modification_count}/{MAX_MODIFICATIONS})> "
                )
                # ëŒ€í™” íˆìŠ¤í† ë¦¬ì— 'assistant'ë¡œ ìˆ˜ì • ì§€ì‹œ ì‚½ì… â†’ ì¬ì§ˆë¬¸ ìœ ë„
                self.conversation_history.append(("user", to_fix))
                ai_resp, ctx = await self.get_ai_response(to_fix)
                self.update_ctx(ctx)
                self.conversation_history.append(("assistant", ai_resp))
                print(f"\nğŸ¤– {ai_resp}")
                # ë‹¤ì‹œ ë£¨í”„
            else:
                print("ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
                return

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì •ë¦¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    async def cleanup(self):
        try:
            if self.agent:
                await self.agents_client.delete_agent(self.agent.id)
        except Exception:
            pass


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë©”ì¸ ì—”íŠ¸ë¦¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async def main():
    assistant = DeepResearchAssistant()
    if not await assistant.initialize():
        return
    try:
        await assistant.chat_loop()
    finally:
        await assistant.cleanup()


if __name__ == "__main__":
    asyncio.run(main())