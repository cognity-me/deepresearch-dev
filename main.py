import asyncio
import os
import sys
import re
import json
from typing import Optional, Dict, List, Tuple, Set
from datetime import datetime
from dotenv import load_dotenv

from azure.ai.projects.aio import AIProjectClient
from azure.ai.agents.aio import AgentsClient
from azure.ai.agents.models import DeepResearchTool, MessageRole, ThreadMessage
from azure.identity.aio import DefaultAzureCredential
from openai import AsyncAzureOpenAI


class DeepResearchAssistant:
    """Advanced Deep Research Assistant with AI-powered conversational interface"""
    
    def __init__(self):
        self.research_context = {
            "topic": None,
            "scope": None,
            "depth": None,
            "format_preferences": None,
            "additional_requirements": [],
            "target_audience": None,
            "key_points": [],
            "constraints": []
        }
        self.conversation_history = []
        self.agents_client = None
        self.agent = None
        self.thread = None
        self.conversation_client = None  # GPT-4o-mini client for conversation
        self.project_client = None
        
    async def initialize(self):
        """Initialize the AI clients and agents"""
        load_dotenv()
        
        # Load environment variables
        try:
            # Deep Research variables
            project_endpoint = os.environ["PROJECT_ENDPOINT"]
            model_deployment_name = os.environ["MODEL_DEPLOYMENT_NAME"]
            deep_research_model = os.environ["DEEP_RESEARCH_MODEL_DEPLOYMENT_NAME"]
            bing_connection_name = os.environ["BING_RESOURCE_NAME"]
            
            # GPT-4o-mini variables for conversation
            gpt4o_mini_key = os.environ["GPT4O_MINI_API_KEY"]
            gpt4o_mini_endpoint = os.environ["GPT4O_MINI_ENDPOINT"]
            gpt4o_mini_deployment = os.environ["GPT4O_MINI_DEPLOYMENT_NAME"]
            
        except KeyError as e:
            print(f"âŒ [ì˜¤ë¥˜] .env íŒŒì¼ì— ë‹¤ìŒ í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {e}")
            return False
            
        # Initialize conversation client (GPT-4o-mini)
        try:
            print("ğŸ”§ ëŒ€í™” ì‹œìŠ¤í…œì„ ì´ˆê¸°í™”í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
            self.conversation_client = AsyncAzureOpenAI(
                api_key=gpt4o_mini_key,
                azure_endpoint=gpt4o_mini_endpoint,
                api_version="2025-01-01-preview"
            )
            self.gpt4o_mini_deployment = gpt4o_mini_deployment
            
        except Exception as e:
            print(f"âŒ ëŒ€í™” ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return False
            
        # Initialize Deep Research clients
        try:
            print("ğŸ”§ Deep Research ì‹œìŠ¤í…œì„ ì´ˆê¸°í™”í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
            self.project_client = AIProjectClient(
                endpoint=project_endpoint,
                credential=DefaultAzureCredential(),
            )
            
            # Get Bing connection
            bing_connection = await self.project_client.connections.get(name=bing_connection_name)
            
            # Define Deep Research tool
            deep_research_tool = DeepResearchTool(
                bing_grounding_connection_id=bing_connection.id,
                deep_research_model=deep_research_model,
            )
            
            # Create agent
            self.agents_client = self.project_client.agents
            self.agent = await self.agents_client.create_agent(
                model=model_deployment_name,
                name="advanced-research-assistant",
                instructions="""You are an advanced research assistant that helps users create comprehensive, 
                professional research reports. You excel at understanding user requirements through natural 
                conversation and producing high-quality, structured reports with tables, charts, and proper citations.""",
                tools=deep_research_tool.definitions,
            )
            
            # Create thread
            self.thread = await self.agents_client.threads.create()
                
            print("âœ… ëª¨ë“  ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ!\n")
            return True
            
        except Exception as e:
            print(f"âŒ Deep Research ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return False
    
    def print_welcome_message(self):
        """Print welcome message and instructions"""
        print("=" * 80)
        print("ğŸ”¬ Advanced Deep Research Assistant with AI Conversation ğŸ”¬".center(80))
        print("=" * 80)
        print("\nì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” ë‹¹ì‹ ì˜ AI ë¦¬ì„œì¹˜ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.")
        print("ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ë¥¼ í†µí•´ ë‹¹ì‹ ì´ ì›í•˜ëŠ” ì—°êµ¬ ì£¼ì œë¥¼ íŒŒì•…í•˜ê³ ,")
        print("ì „ë¬¸ì ì´ê³  ê¹Šì´ ìˆëŠ” ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ë“œë¦½ë‹ˆë‹¤.\n")
        print("ğŸ’¡ ì‚¬ìš© ë°©ë²•:")
        print("  - ì—°êµ¬í•˜ê³  ì‹¶ì€ ì£¼ì œë‚˜ ê¶ê¸ˆí•œ ì ì„ ììœ ë¡­ê²Œ ë§ì”€í•´ì£¼ì„¸ìš”")
        print("  - ëŒ€í™”ë¥¼ í†µí•´ í•„ìš”í•œ ì •ë³´ë¥¼ íŒŒì•…í•˜ê² ìŠµë‹ˆë‹¤")
        print("  - 'exit' ë˜ëŠ” 'ì¢…ë£Œ'ë¥¼ ì…ë ¥í•˜ë©´ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤\n")
        print("-" * 80)
    
    async def get_user_input(self, prompt: str = "\nğŸ’¬ ë‹¹ì‹ : ") -> str:
        """Get user input with a custom prompt"""
        return await asyncio.get_event_loop().run_in_executor(None, input, prompt)
    
    async def get_ai_response(self, user_message: str) -> Tuple[str, Dict]:
        """Get AI response using GPT-4o-mini and function calling for structured context."""
        
        tools = [
            {
                "type": "function",
                "function": {
                    "name": "update_research_context",
                    "description": "Updates the research context with information gathered from the user. Only call this when you have new or updated information.",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "topic": {
                                "type": "string",
                                "description": "The main topic of the research. e.g., 'í•œêµ­ì˜ ì €ì¶œì‚° ë¬¸ì œ'"
                            },
                            "scope": {
                                "type": "string",
                                "description": "The scope or time period for the research. e.g., '2010ë…„ëŒ€ ì´í›„'"
                            },
                            "depth": {
                                "type": "string",
                                "description": "The desired depth of analysis. e.g., 'ì‹¬ì¸µ ë¶„ì„'"
                            },
                            "target_audience": {
                                "type": "string",
                                "description": "The target audience for the report. e.g., 'ì •ì±… ì…ì•ˆì'"
                            },
                            "is_ready": {
                                "type": "boolean",
                                "description": "Set to true only when enough information (at least topic and scope) is gathered to start the research."
                            }
                        },
                        "required": ["is_ready"]
                    }
                }
            }
        ]

        context_summary = []
        if self.research_context["topic"]:
            context_summary.append(f"ì£¼ì œ: {self.research_context['topic']}")
        if self.research_context["scope"]:
            context_summary.append(f"ë²”ìœ„: {self.research_context['scope']}")
        if self.research_context["depth"]:
            context_summary.append(f"ê¹Šì´: {self.research_context['depth']}")
        if self.research_context["target_audience"]:
            context_summary.append(f"ëŒ€ìƒ: {self.research_context['target_audience']}")

        current_context = "\n".join(context_summary) if context_summary else "ì•„ì§ ìˆ˜ì§‘ëœ ì •ë³´ ì—†ìŒ"

        system_prompt = f"""You are a friendly and masterful research assistant. Your primary goal is to proactively guide the user to define their research needs through a natural, question-driven conversation in Korean.

        CURRENT COLLECTED INFORMATION:
        {current_context}

        YOUR TASK:
        1.  **Always ask a clear, guiding question.** Your response must always lead the conversation forward. Never be passive.
            - Good Example: "ì‚¬íšŒ ë¬¸ì œì— ëŒ€í•´ ì•Œì•„ë³´ê³  ì‹¶ìœ¼ì‹œêµ°ìš”. í˜¹ì‹œ íŠ¹ì • ê¸°ê°„ì´ë‚˜ ë²”ìœ„ì— ê´€ì‹¬ì´ ìˆìœ¼ì‹ ê°€ìš”?"
            - Bad Example: "ì•Œê² ìŠµë‹ˆë‹¤." or "ì •ë³´ë¥¼ ì—…ë°ì´íŠ¸í–ˆìŠµë‹ˆë‹¤."
        2.  Gather the following details one by one:
            - topic (ì£¼ì œ) - REQUIRED
            - scope (ë²”ìœ„/ê¸°ê°„) - REQUIRED
            - depth (ë¶„ì„ ê¹Šì´) - Optional
            - target_audience (ëŒ€ìƒ) - Optional
        3.  **When you gather or update any information, you MUST call the `update_research_context` tool.** You must also provide a conversational response *in addition* to the tool call.
        4.  If the user's request is ambiguous (e.g., just "ì‚¬íšŒë¬¸ì œ"), interpret it broadly for the context update (e.g., set topic to "í•œêµ­ ì‚¬íšŒë¬¸ì œ ì „ë°˜"), and then immediately ask a clarifying question to narrow it down (e.g., ask about "ì €ì¶œì‚°" or "ê³ ë ¹í™”").
        5.  Once you have at least the topic and scope, you can set `is_ready` to `true` in your tool call.
        6.  Keep your conversational responses SHORT and TO THE POINT (1-2 sentences).
        7.  Do NOT ask about information you have already collected.
        """

        messages = [{"role": "system", "content": system_prompt}]
        for role, content in self.conversation_history[-6:]:
            messages.append({"role": role, "content": content})
        messages.append({"role": "user", "content": user_message})

        try:
            response = await self.conversation_client.chat.completions.create(
                model=self.gpt4o_mini_deployment,
                messages=messages,
                tools=tools,
                tool_choice="auto",
                temperature=0.7,
                max_tokens=500
            )
            
            response_message = response.choices[0].message
            ai_response = response_message.content or ""
            context_data = {"is_ready": False}

            if response_message.tool_calls:
                tool_call = response_message.tool_calls[0]
                if tool_call.function.name == "update_research_context":
                    try:
                        tool_args = json.loads(tool_call.function.arguments)
                        
                        temp_context = {}
                        temp_context["topic"] = tool_args.get("topic")
                        temp_context["scope"] = tool_args.get("scope")
                        temp_context["depth"] = tool_args.get("depth")
                        temp_context["target_audience"] = tool_args.get("target_audience")
                        temp_context["is_ready"] = tool_args.get("is_ready", False)

                        context_data = temp_context
                        
                        if not ai_response:
                            ai_response = "ë” êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì‹œê² ì–´ìš”? ì–´ë–¤ ì ì´ ê¶ê¸ˆí•˜ì‹ ê°€ìš”?"
                            
                    except json.JSONDecodeError:
                        print("âš ï¸ [ê²½ê³ ] AIë¡œë¶€í„° ë°›ì€ ë„êµ¬ ì¸ì(tool arguments) íŒŒì‹±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                        ai_response = "ì •ë³´ë¥¼ ì²˜ë¦¬í•˜ëŠ” ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."
            
            return ai_response, context_data

        except Exception as e:
            print(f"âŒ AI ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return "ì£„ì†¡í•©ë‹ˆë‹¤. ë‹¤ì‹œ ë§ì”€í•´ì£¼ì‹œê² ì–´ìš”?", {"is_ready": False}
    
    def update_research_context_from_ai(self, context_data: Dict):
        """Update research context based on AI-extracted information"""
        # Update topic
        if context_data.get("topic"):
            # Always update if AI provides a topic (might be more specific)
            self.research_context["topic"] = context_data["topic"]
            
        # Update scope
        if context_data.get("scope"):
            # Always update if AI provides scope
            self.research_context["scope"] = context_data["scope"]
            
        # Update depth
        if context_data.get("depth") and context_data["depth"] not in ['None', 'string']:
            self.research_context["depth"] = context_data["depth"]
            
        # Update target audience
        if context_data.get("target_audience") and context_data["target_audience"] not in ['None', 'string']:
            self.research_context["target_audience"] = context_data["target_audience"]
            
        # Update format preferences
        if context_data.get("format_preferences"):
            self.research_context["format_preferences"] = context_data["format_preferences"]
            
        # Update key points
        if context_data.get("key_points"):
            # Add new key points without duplicates
            for point in context_data["key_points"]:
                if point and point not in self.research_context["key_points"]:
                    self.research_context["key_points"].append(point)
    
    def create_research_prompt(self) -> str:
        """Create a comprehensive research prompt based on collected information"""
        prompt_parts = []
        
        # Main topic
        if self.research_context["topic"]:
            prompt_parts.append(f"Research Topic: {self.research_context['topic']}")
        
        # Scope and timeframe
        if self.research_context["scope"]:
            prompt_parts.append(f"Scope and Timeframe: {self.research_context['scope']}")
            
        # Depth of analysis
        if self.research_context["depth"]:
            prompt_parts.append(f"Analysis Depth: {self.research_context['depth']}")
            
        # Target audience
        if self.research_context["target_audience"]:
            prompt_parts.append(f"Target Audience: {self.research_context['target_audience']}")
            
        # Key points to cover
        if self.research_context["key_points"]:
            prompt_parts.append(f"Key Points to Address: {', '.join(self.research_context['key_points'])}")
            
        # Professional report structure
        prompt_parts.append("""
Please create a comprehensive research report that includes:

1. **Executive Summary** (í•µì‹¬ ìš”ì•½)
   - Key findings at a glance
   - Main recommendations

2. **Table of Contents** (ëª©ì°¨)

3. **Introduction and Background** (ì„œë¡  ë° ë°°ê²½)
   - Context and importance
   - Research objectives

4. **Methodology** (ì—°êµ¬ ë°©ë²•ë¡ )
   - Data sources and approach

5. **Main Findings** (ì£¼ìš” ë°œê²¬ì‚¬í•­)
   - Organized in clear, logical sections
   - Use subheadings for different aspects

6. **Data Analysis** (ë°ì´í„° ë¶„ì„)
   - Include relevant tables with clear headers
   - Describe trends and patterns
   - Use markdown tables for data presentation

7. **Visual Insights** (ì‹œê°ì  í†µì°°)
   - Describe charts/graphs that would be helpful
   - Explain what each visualization would show

8. **Comparative Analysis** (ë¹„êµ ë¶„ì„)
   - Compare different approaches/solutions/trends
   - Use comparison tables where appropriate

9. **Challenges and Limitations** (ë„ì „ê³¼ì œ ë° í•œê³„)

10. **Conclusions and Recommendations** (ê²°ë¡  ë° ì œì–¸)
    - Clear, actionable insights
    - Future outlook

11. **References** (ì°¸ê³ ë¬¸í—Œ)
    - All sources with proper citations
    - Use [1], [2], etc. for in-text citations

**Formatting Requirements:**
- Use clear markdown formatting with proper headers (##, ###)
- Include bullet points and numbered lists for clarity
- Create tables using markdown table syntax
- Bold important terms and concepts
- Include relevant statistics and data points
- Ensure all claims are backed by citations
""")
        
        # Special format requirements
        if self.research_context["format_preferences"]:
            prompt_parts.append(f"\nSpecial Format Requirements: {self.research_context['format_preferences']}")
            
        # Language preference (Korean-focused but with English terms where appropriate)
        prompt_parts.append("\nPlease write the report primarily in Korean, but use English technical terms where appropriate for clarity.")
            
        return "\n".join(prompt_parts)
    
    async def generate_research_plan(self) -> str:
        """Generates a detailed, context-aware research plan using an LLM call."""
        
        context = self.research_context
        prompt = f"""
        ë‹¹ì‹ ì€ ì „ë¬¸ ë¦¬ì„œì¹˜ ê¸°íšìì…ë‹ˆë‹¤. ì•„ë˜ ì‚¬ìš©ìê°€ ìˆ˜ì§‘í•œ ì—°êµ¬ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì „ë¬¸ì ì´ê³  ìƒì„¸í•œ ì—°êµ¬ ë³´ê³ ì„œ ëª©ì°¨(ê³„íš)ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

        **ìˆ˜ì§‘ëœ ì—°êµ¬ ì»¨í…ìŠ¤íŠ¸:**
        - ì£¼ì œ: {context['topic']}
        - ë²”ìœ„: {context.get('scope', 'ì „ì²´')}
        - ë¶„ì„ ê¹Šì´: {context.get('depth', 'í‘œì¤€')}
        - ëŒ€ìƒ ë…ì: {context.get('target_audience', 'ì¼ë°˜')}
        - í•µì‹¬ í¬ì¸íŠ¸: {', '.join(context['key_points']) if context['key_points'] else 'ì§€ì •ë˜ì§€ ì•ŠìŒ'}

        **ì§€ì¹¨:**
        1.  **ëª©ì°¨ í˜•ì‹ìœ¼ë¡œ** ì‘ì„±í•´ì£¼ì„¸ìš”. (ì˜ˆ: 1. ì„œë¡ , 1-1. ì—°êµ¬ ë°°ê²½, 2. ë³¸ë¡ ...)
        2.  ê° ëª©ì°¨ í•­ëª©ì— **ì–´ë–¤ ë‚´ìš©ì´ ë“¤ì–´ê°ˆì§€ í•œë‘ ë¬¸ì¥ìœ¼ë¡œ êµ¬ì²´ì ì¸ ì„¤ëª…**ì„ ë§ë¶™ì—¬ì£¼ì„¸ìš”.
        3.  ì»¨í…ìŠ¤íŠ¸(ì£¼ì œ, ë²”ìœ„ ë“±)ë¥¼ ì ê·¹ì ìœ¼ë¡œ ë°˜ì˜í•˜ì—¬ **ê°œì¸í™”ëœ ê³„íš**ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”.
        4.  ê²°ê³¼ëŠ” ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì˜ ë²ˆí˜¸ ë§¤ê¸°ê¸° ëª©ë¡ìœ¼ë¡œ ì¶œë ¥í•´ì£¼ì„¸ìš”.

        **ì˜ˆì‹œ:**
        1.  **ì„œë¡ **
            -   í•œêµ­ì˜ ì €ì¶œì‚° ë¬¸ì œê°€ êµ­ê°€ì  ìœ„ê¸°ë¡œ ëŒ€ë‘ëœ ë°°ê²½ê³¼ ì‹¬ê°ì„±ì„ ì„¤ëª…í•©ë‹ˆë‹¤.
            -   ë³¸ ì—°êµ¬ì˜ ëª©ì ê³¼ ë²”ìœ„ë¥¼ ëª…í™•íˆ ì œì‹œí•©ë‹ˆë‹¤.
        2.  **ì§€ë‚œ 10ë…„ê°„ ì €ì¶œì‚° ì •ì±… ë¶„ì„**
            -   ì£¼ìš” ì •ì±…ë“¤(ì˜ˆ: ë³´ìœ¡ ì§€ì›, ì£¼ê±° ì§€ì›)ì„ ì‹œê¸°ë³„ë¡œ ì •ë¦¬í•˜ê³  ë‚´ìš©ì„ ë¶„ì„í•©ë‹ˆë‹¤.
            -   ê° ì •ì±…ì˜ ì„±ê³¼ì™€ í•œê³„ë¥¼ í†µê³„ ìë£Œë¥¼ ê¸°ë°˜ìœ¼ë¡œ í‰ê°€í•©ë‹ˆë‹¤.
        
        ì´ì œ ìœ„ì˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì—°êµ¬ ê³„íšì„ ì‘ì„±í•´ì£¼ì„¸ìš”.
        """

        messages = [{"role": "user", "content": prompt}]
        
        try:
            response = await self.conversation_client.chat.completions.create(
                model=self.gpt4o_mini_deployment,
                messages=messages,
                temperature=0.5,
            )
            plan = response.choices[0].message.content
            return plan
        except Exception as e:
            print(f"âŒ ì—°êµ¬ ê³„íš ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return "ì—°êµ¬ ê³„íšì„ ìƒì„±í•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ê¸°ë³¸ ëª©ì°¨ë¡œ ì§„í–‰í•©ë‹ˆë‹¤."

    async def conduct_research(self, research_prompt: str) -> Optional[ThreadMessage]:
        """Conduct the actual deep research"""
        print("\nğŸ” Deep Researchë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
        print("=" * 80)
        
        # Create message in thread
        await self.agents_client.messages.create(
            thread_id=self.thread.id,
            role="user",
            content=research_prompt,
        )
        
        # Start the run
        run = await self.agents_client.runs.create(
            thread_id=self.thread.id,
            agent_id=self.agent.id
        )
        
        # Progress indicators
        progress_indicators = ["â ‹", "â ™", "â ¹", "â ¸", "â ¼", "â ´", "â ¦", "â §", "â ‡", "â "]
        progress_index = 0
        printed_step_ids: Set[str] = set()
        start_time = datetime.now()
        
        # Poll for completion
        while run.status in ("queued", "in_progress"):
            await asyncio.sleep(2)
            run = await self.agents_client.runs.get(thread_id=self.thread.id, run_id=run.id)
            
            # Show progress spinner
            elapsed = (datetime.now() - start_time).seconds
            minutes = elapsed // 60
            seconds = elapsed % 60
            
            if minutes > 0:
                time_str = f"{minutes}ë¶„ {seconds}ì´ˆ"
            else:
                time_str = f"{seconds}ì´ˆ"
                
            print(f"\r{progress_indicators[progress_index % len(progress_indicators)]} "
                  f"Deep Research ì§„í–‰ ì¤‘... ({time_str} ê²½ê³¼) | ìƒíƒœ: {run.status}", 
                  end="", flush=True)
            progress_index += 1
            
            # Check for and print new run steps (Chain of Thought)
            try:
                run_steps = self.agents_client.runs.steps.list(thread_id=self.thread.id, run_id=run.id)
                async for step in run_steps:
                    if step.id not in printed_step_ids:
                        # A new step is found, break from the spinner line
                        print("\n\n" + "="*80)
                        
                        step_type_korean = "ì•Œ ìˆ˜ ì—†ìŒ"
                        if step.step_details:
                            step_type_korean = "íˆ´ í˜¸ì¶œ" if step.step_details.type == 'tool_calls' else "ë©”ì‹œì§€ ìƒì„±"

                        print(f"ğŸ§  AI ì‘ì—… ë‹¨ê³„ í¬ì°© (ìƒíƒœ: {step.status})")
                        print(f"   - ì¢…ë¥˜: {step_type_korean}")

                        # If the step involves tool calls, print their details
                        if step.step_details and step.step_details.type == 'tool_calls':
                            for tool_call in step.step_details.tool_calls:
                                if hasattr(tool_call, 'deep_research') and tool_call.deep_research:
                                    details = tool_call.deep_research
                                    print("   - íˆ´: Deep Research")
                                    # `details` is a dict-like object, print its key-value pairs
                                    for key, value in details.items():
                                        print(f"     - {key}: {str(value).strip()}")

                        print("="*80 + "\n")
                        sys.stdout.flush()
                        printed_step_ids.add(step.id)
            except Exception:
                # Do not break the main loop for logging errors
                pass
        
        print(f"\nâœ… Deep Research ì™„ë£Œ! (ì´ ì†Œìš”ì‹œê°„: {minutes}ë¶„ {seconds}ì´ˆ)")
        
        if run.status == "failed":
            print(f"âŒ ë¦¬ì„œì¹˜ ì‹¤íŒ¨: {run.last_error}")
            return None
            
        # Get final message
        final_message = await self.agents_client.messages.get_last_message_by_role(
            thread_id=self.thread.id,
            role=MessageRole.AGENT
        )
        
        return final_message
    
    def enhance_report_formatting(self, content: str) -> str:
        """Enhance the report with better formatting and structure"""
        # Add timestamp and metadata
        timestamp = datetime.now().strftime("%Yë…„ %mì›” %dì¼ %H:%M")
        
        # Create professional header
        header = f"""<div align="center">

# ğŸ“Š Research Report

### {self.research_context['topic']}

---

**ì‘ì„±ì¼**: {timestamp}  
**ëŒ€ìƒ ë…ì**: {self.research_context.get('target_audience', 'ì¼ë°˜')}  
**ë¶„ì„ ë²”ìœ„**: {self.research_context.get('scope', 'í¬ê´„ì ')}  
**ë¶„ì„ ê¹Šì´**: {self.research_context.get('depth', 'í‘œì¤€')}

</div>

---

"""
        
        # Add CSS-like styling for better markdown rendering
        style_section = """
<style>
table {
    border-collapse: collapse;
    width: 100%;
    margin: 20px 0;
}
th {
    background-color: #4CAF50;
    color: white;
    font-weight: bold;
    padding: 12px;
    text-align: left;
    border: 1px solid #ddd;
}
td {
    padding: 12px;
    border: 1px solid #ddd;
}
tr:nth-child(even) {
    background-color: #f2f2f2;
}
tr:hover {
    background-color: #e8f5e9;
}
.highlight {
    background-color: #fff3cd;
    padding: 10px;
    border-left: 4px solid #ffc107;
    margin: 10px 0;
}
.important {
    color: #d32f2f;
    font-weight: bold;
}
</style>

"""
        
        # Process content to enhance formatting
        enhanced_content = content
        
        # Add emoji indicators for sections
        section_emojis = {
            "Executive Summary": "ğŸ“‹",
            "í•µì‹¬ ìš”ì•½": "ğŸ“‹",
            "Table of Contents": "ğŸ“‘",
            "ëª©ì°¨": "ğŸ“‘",
            "Introduction": "ğŸ¯",
            "ì„œë¡ ": "ğŸ¯",
            "Methodology": "ğŸ”¬",
            "ì—°êµ¬ ë°©ë²•ë¡ ": "ğŸ”¬",
            "Main Findings": "ğŸ”",
            "ì£¼ìš” ë°œê²¬ì‚¬í•­": "ğŸ”",
            "Data Analysis": "ğŸ“Š",
            "ë°ì´í„° ë¶„ì„": "ğŸ“Š",
            "Visual Insights": "ğŸ“ˆ",
            "ì‹œê°ì  í†µì°°": "ğŸ“ˆ",
            "Comparative Analysis": "âš–ï¸",
            "ë¹„êµ ë¶„ì„": "âš–ï¸",
            "Challenges": "âš ï¸",
            "ë„ì „ê³¼ì œ": "âš ï¸",
            "Conclusions": "âœ…",
            "ê²°ë¡ ": "âœ…",
            "References": "ğŸ“š",
            "ì°¸ê³ ë¬¸í—Œ": "ğŸ“š"
        }
        
        for section, emoji in section_emojis.items():
            enhanced_content = enhanced_content.replace(f"## {section}", f"## {emoji} {section}")
            enhanced_content = enhanced_content.replace(f"### {section}", f"### {emoji} {section}")
        
        return header + style_section + enhanced_content
    
    def save_report(self, message: ThreadMessage, filename: str = None) -> str:
        """Save the research report to a file"""
        if not message:
            return None
            
        # Generate filename
        if not filename:
            safe_topic = re.sub(r'[^\w\s-]', '', self.research_context["topic"])
            safe_topic = re.sub(r'[-\s]+', '-', safe_topic)[:50]  # Limit length
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"research_report_{safe_topic}_{timestamp}.md"
        
        try:
            with open(filename, "w", encoding="utf-8") as fp:
                # Combine all text messages
                content = "\n\n".join([t.text.value.strip() for t in message.text_messages])
                
                # Enhance formatting
                enhanced_content = self.enhance_report_formatting(content)
                fp.write(enhanced_content)
                
                # Add citations section with better formatting
                if message.url_citation_annotations:
                    fp.write("\n\n---\n\n## ğŸ“š ì°¸ê³ ë¬¸í—Œ (References)\n\n")
                    fp.write("| No. | Title | Source | URL |\n")
                    fp.write("|-----|-------|--------|-----|\n")
                    
                    seen_urls = set()
                    for i, ann in enumerate(message.url_citation_annotations, 1):
                        url = ann.url_citation.url
                        title = ann.url_citation.title or "Untitled"
                        if url not in seen_urls:
                            # Extract domain from URL for source
                            domain_match = re.search(r'https?://([^/]+)', url)
                            source = domain_match.group(1) if domain_match else "Web"
                            
                            fp.write(f"| [{i}] | {title[:50]}{'...' if len(title) > 50 else ''} | {source} | [Link]({url}) |\n")
                            seen_urls.add(url)
                            
                # Add footer
                fp.write(f"\n\n---\n\n")
                fp.write(f"<div align='center'>\n\n")
                fp.write(f"*ì´ ë³´ê³ ì„œëŠ” **Advanced Deep Research Assistant**ì— ì˜í•´ ìë™ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.*\n\n")
                fp.write(f"*Powered by Azure OpenAI GPT-4o & Deep Research*\n\n")
                fp.write(f"</div>")
                
            return filename
            
        except IOError as e:
            print(f"âŒ íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return None
    
    async def chat_loop(self):
        """Main chat loop for AI-powered interaction with user"""
        self.print_welcome_message()
        
        # Initial greeting - more concise
        print("\nğŸ¤– AI ì–´ì‹œìŠ¤í„´íŠ¸: ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ì—°êµ¬í•˜ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?")

        # ìˆ˜ì • ìš”ì²­ íšŸìˆ˜ ì¹´ìš´í„°
        modification_count = 0  # ìµœëŒ€ 10íšŒê¹Œì§€ í—ˆìš©
        
        while True:
            # Get user input
            user_input = await self.get_user_input()
            
            # Check for exit
            if user_input.lower() in ['exit', 'quit', 'ì¢…ë£Œ', 'ë', 'ë‚˜ê°€ê¸°']:
                print("\nğŸ‘‹ ë¦¬ì„œì¹˜ ì–´ì‹œìŠ¤í„´íŠ¸ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤. ì¢‹ì€ í•˜ë£¨ ë˜ì„¸ìš”!")
                break
            
            # Add to conversation history
            self.conversation_history.append(("user", user_input))
            
            # Get AI response and context extraction
            ai_response, context_data = await self.get_ai_response(user_input)
            
            # Update research context
            self.update_research_context_from_ai(context_data)
            
            # Add AI response to history
            self.conversation_history.append(("assistant", ai_response))
            
            # Print AI response
            print(f"\nğŸ¤– AI ì–´ì‹œìŠ¤í„´íŠ¸: {ai_response}")
            
            # Check if ready for research AND has topic
            if context_data.get("is_ready", False) and self.research_context["topic"]:
                
                # Loop for modifying the research plan
                while modification_count < 10:
                    print("\n" + "="*80)
                    print("ğŸ“‹ ì—°êµ¬ ê³„íš ì œì•ˆ")
                    print("="*80)
                    
                    print(f"ğŸ“Œ ì£¼ì œ: {self.research_context['topic']}")
                    print(f"ğŸ“… ë²”ìœ„: {self.research_context.get('scope', 'ì „ì²´ ê¸°ê°„')}")
                    print(f"ğŸ“Š ë¶„ì„ ê¹Šì´: {self.research_context.get('depth', 'í‘œì¤€ ë¶„ì„')}")
                    print(f"ğŸ‘¥ ëŒ€ìƒ ë…ì: {self.research_context.get('target_audience', 'ì¼ë°˜ ë…ì')}")
                    
                    if self.research_context['key_points']:
                        print(f"\nğŸ”‘ í•µì‹¬ í¬ì¸íŠ¸:")
                        for i, point in enumerate(self.research_context['key_points'][:5], 1):
                            print(f"   {i}. {point}")
                    
                    print("\nğŸ“‘ ì œì•ˆ ëª©ì°¨:")
                    detailed_plan = await self.generate_research_plan()
                    print(detailed_plan)
                    print("="*80)
                    
                    user_choice = await self.get_user_input("\nâœ… ì´ ê³„íšìœ¼ë¡œ ë¦¬ì„œì¹˜ë¥¼ ì‹œì‘í• ê¹Œìš”? (Enter: ì‹œì‘, 'ìˆ˜ì •': ìˆ˜ì •í•˜ê¸°): ")

                    if user_choice.lower() != 'ìˆ˜ì •':
                        break  # Exit modification loop to start research
                    else:
                        modification_count += 1
                        if modification_count >= 10:
                            print("\nâš ï¸ ìˆ˜ì • ìš”ì²­ì´ 10íšŒë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ë§ˆì§€ë§‰ ê³„íšìœ¼ë¡œ ìë™ ì§„í–‰í•©ë‹ˆë‹¤.")
                            break

                        mod_request = await self.get_user_input("\nğŸ¤– AI ì–´ì‹œìŠ¤í„´íŠ¸: ì•Œê² ìŠµë‹ˆë‹¤. ì–´ë–¤ ë¶€ë¶„ì„ ìˆ˜ì •í•˜ê³  ì‹¶ìœ¼ì‹ ê°€ìš”? ììœ ë¡­ê²Œ ë§ì”€í•´ì£¼ì„¸ìš”: ")
                        self.conversation_history.append(("user", mod_request))
                        ai_response, context_data = await self.get_ai_response(mod_request)
                        self.update_research_context_from_ai(context_data)
                        self.conversation_history.append(("assistant", ai_response))
                        print(f"\nğŸ¤– AI ì–´ì‹œìŠ¤í„´íŠ¸: {ai_response}")
                        # Continue modification loop
                
                # --- Start Research ---
                research_prompt = self.create_research_prompt()
                final_message = await self.conduct_research(research_prompt)
                
                if final_message:
                    filename = self.save_report(final_message)
                    if filename:
                        print(f"\nâœ… ë³´ê³ ì„œê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
                        print(f"ğŸ“„ íŒŒì¼ëª…: {filename}")
                        
                        print("\n" + "="*80)
                        print("ğŸ“– ë³´ê³ ì„œ ë¯¸ë¦¬ë³´ê¸°")
                        print("="*80)
                        
                        preview_text = "\n".join([t.text.value.strip() for t in final_message.text_messages])
                        preview_lines = preview_text[:800].split('\n')
                        for line in preview_lines[:15]:
                            if line.strip():
                                print(line)
                        
                        print("\n... (ì „ì²´ ë‚´ìš©ì€ íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”)")
                        print("="*80)
                
                # Ask if user wants to continue
                continue_input = await self.get_user_input("\nìƒˆë¡œìš´ ì—°êµ¬ë¥¼ ì‹œì‘í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (yes/no): ")
                if continue_input.lower() in ['no', 'n', 'ì•„ë‹ˆì˜¤', 'ì•„ë‹ˆìš”']:
                    print("\nğŸ‘‹ ê°ì‚¬í•©ë‹ˆë‹¤. ì¢‹ì€ í•˜ë£¨ ë˜ì„¸ìš”!")
                    break
                else:
                    self.research_context = {
                        "topic": None,
                        "scope": None,
                        "depth": None,
                        "format_preferences": None,
                        "additional_requirements": [],
                        "target_audience": None,
                        "key_points": [],
                        "constraints": []
                    }
                    self.conversation_history = []
                    modification_count = 0
                    print("\nğŸ”„ ìƒˆë¡œìš´ ì—°êµ¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")
                    print("\nğŸ¤– AI ì–´ì‹œìŠ¤í„´íŠ¸: ì–´ë–¤ ì£¼ì œë¥¼ ì—°êµ¬í•˜ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?")
    
    async def cleanup(self):
        """Clean up resources"""
        if self.agent and self.agents_client:
            try:
                await self.agents_client.delete_agent(self.agent.id)
                print("\nğŸ§¹ Agent ë¦¬ì†ŒìŠ¤ê°€ ì •ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
            except Exception as e:
                print(f"âš ï¸ Agent ì •ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

        # Close clients
        if self.project_client:
            try:
                await self.project_client.close()
                print("ğŸ§¹ Deep Research client ì—°ê²°ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            except Exception as e:
                print(f"âš ï¸ Deep Research client ì¢…ë£Œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

        if self.conversation_client:
            try:
                await self.conversation_client.close()
                print("ğŸ§¹ Conversation client ì—°ê²°ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            except Exception as e:
                print(f"âš ï¸ Conversation client ì¢…ë£Œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")


async def main():
    """Main entry point"""
    assistant = DeepResearchAssistant()
    
    # Initialize the system
    if not await assistant.initialize():
        return
    
    try:
        # Start the chat loop
        await assistant.chat_loop()
    finally:
        # Clean up
        await assistant.cleanup()


if __name__ == "__main__":
    # Run the async main function
    asyncio.run(main()) 